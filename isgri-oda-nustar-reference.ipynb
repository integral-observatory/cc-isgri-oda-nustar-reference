{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "subcases_pattern=\"1461_Nustar\"\n",
    "reference_location=\"../..\"\n",
    "source_name=\"Crab\"\n",
    "osa_version='OSA10.2'\n",
    "nscw=3\n",
    "mosaic=0\n",
    "chi2_limit=1.2\n",
    "systematic_fraction=0.01\n",
    "search_time=-1 #search time of INTEGRAL DATA around the time of observation (days), if -1 uses the actual interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reference_location == 'None':\n",
    "    import subprocess\n",
    "    logfile_name = 'log_download_reference.txt'\n",
    "    logfile = open(logfile_name, 'w')\n",
    "    cmd = 'wget https://www.isdc.unige.ch/~ferrigno/Downloads/subcases_herX1_nustar.tgz;tar xfz subcases_herX1_nustar.tgz;rm subcases_herX1_nustar.tgz'\n",
    "    # cmd='pwd;ls'\n",
    "    out = subprocess.call(cmd, stdout=logfile, stderr=logfile, shell=True)\n",
    "    logfile.close()\n",
    "    if out != 0:\n",
    "        print('Exit status of download and decompression is %d')\n",
    "        raise RuntimeError\n",
    "    \n",
    "    reference_location='.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ISGRI verification with NuSTAR reference\n",
    "\n",
    "simultaneous observations allow easy comparisong\n",
    "\n",
    "normalization need to be fitted and reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy import coordinates as coord\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from astropy.io import fits as pf\n",
    "from astropy.time import Time\n",
    "from astropy.time import TimeDelta\n",
    "\n",
    "from astropy import table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "url=\"https://www.astro.unige.ch/cdci/astrooda/dispatch-data/gw/timesystem/api/v1.0/scwlist/cons/\"\n",
    "def get_scw_list(subcase_dir, ra,dec,time, delta_time): #time in UTC T (2019-06-23T16:53:39.000), deltat in days\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        scwlist = open(subcase_dir+\"/ISGRI_scw_list.txt\").read().split()\n",
    "        print(\"read scw list from \" + subcase_dir+\"/ISGRI_scw_list.txt\")\n",
    "        return scwlist\n",
    "    except:\n",
    "\n",
    "\n",
    "    #     result_table = Simbad.query_object(source_name)\n",
    "    #     source_coord = coord.SkyCoord(result_table['RA'][0], result_table['DEC'][0], unit=(\"hourangle\", \"deg\"))\n",
    "\n",
    "    #     ra=source_coord.ra.deg\n",
    "    #     dec=source_coord.dec.deg\n",
    "\n",
    "        dt = TimeDelta(delta_time)\n",
    "\n",
    "        Tstart = Time(time) - dt\n",
    "        Tstop  = Time(time) + dt\n",
    "\n",
    "        Tstart.format='isot'\n",
    "        Tstop.format='isot'\n",
    "\n",
    "\n",
    "        params=Tstart.value+'/'+Tstop.value+'?&ra='+str(ra)+'&dec='+str(dec)+'&radius='+str(6.0)+'&min_good_isgri=1000'\n",
    "        print(\"Obtained scw list online from \" + url+params)\n",
    "        return requests.get(url+params).json() #,cookies=cookies).json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_location\n",
    "\n",
    "# if reference_location  not git or http may be a problem\n",
    "# dependency injection for this, if can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subcase=None\n",
    "reference_spectra = None\n",
    "\n",
    "for subcase_dir in glob.glob(reference_location+\"/subcases/*\"+subcases_pattern+\"*\"):\n",
    "    print(\"inspecting\", subcase_dir)\n",
    "    \n",
    "    fns = [os.path.basename(fn) for fn in sorted(glob.glob(subcase_dir+\"/*\"))]\n",
    "    \n",
    "    try:\n",
    "        #If it is rebinned with my script\n",
    "        reference_spectra = [fn for fn in fns if fn.endswith(\"rbn.pi\")]\n",
    "        \n",
    "        reference_rmfs = [fn for fn in fns if fn.endswith(\"sr.rmf\") or fn.endswith(\"sr.rmf.gz\")]\n",
    "        \n",
    "        reference_arfs = [fn for fn in fns if fn.endswith(\"sr.arf\")]\n",
    "        \n",
    "        reference_backs = [fn for fn in fns if fn.endswith(\"bk.pha\")]\n",
    "        \n",
    "    except: \n",
    "        print(\"Not found Nustar Files in \" + subcase_dir)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        print(subcase_dir+'/'+reference_spectra[0])\n",
    "        spec=pf.open(subcase_dir+'/'+reference_spectra[0])\n",
    "\n",
    "        t1=Time(spec[1].header['DATE-OBS'])\n",
    "        t2=Time(spec[1].header['DATE-END'])\n",
    "\n",
    "        ra=spec[1].header['RA_OBJ']\n",
    "        dec=spec[1].header['DEC_OBJ']\n",
    "\n",
    "        delta_time = (t2 - t1 )/2\n",
    "\n",
    "        time=t1+delta_time\n",
    "\n",
    "        spec.close()\n",
    "\n",
    "        if search_time == -1:\n",
    "            scwlist= get_scw_list(subcase_dir, ra,dec, time, delta_time)\n",
    "        else:\n",
    "            scwlist= get_scw_list(subcase_dir, ra,dec, time, search_time)\n",
    "        \n",
    "        print(t1, time)\n",
    "        \n",
    "        #print(scwlist)\n",
    "    except:\n",
    "        print(\"Not getting times\")\n",
    "        continue\n",
    "    \n",
    "   \n",
    "        \n",
    "    #print(fns)\n",
    "    \n",
    "    reference_dir=subcase_dir\n",
    "    \n",
    "    #print(\"found\",reference_dir, reference_spectra, len(scwlist),len(ref_sources), ref_sources)\n",
    "        \n",
    "    break\n",
    "        \n",
    "if len(list(zip(reference_spectra, reference_backs, reference_rmfs, reference_arfs))) == 0:\n",
    "    raise Exception(f\"no compatible NuSTAR spectra found; last fns tried {fns}\")\n",
    "#reference_spectra, reference_rmfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"searching for coordinates of\", source_name)\n",
    "\n",
    "result_table = Simbad.query_object(source_name)\n",
    "source_coord = coord.SkyCoord(result_table['RA'][0], result_table['DEC'][0], unit=(\"hourangle\", \"deg\"))\n",
    "\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "if nscw >0:\n",
    "    random.seed(0)\n",
    "    cleaned_list = [\n",
    "                s+\".\"+\"001\"\n",
    "                for s in list(sorted(set( scwlist  ))) \n",
    "                if s.endswith(\"0010\")\n",
    "            ]\n",
    "    if len(cleaned_list) > nscw:\n",
    "        scw_pick = random.sample(cleaned_list,nscw)\n",
    "    else:\n",
    "        print(\"nscw (%d) > than available scw (%d), using them all\"%(nscw,len(cleaned_list)))\n",
    "        scw_pick = cleaned_list\n",
    "\n",
    "\n",
    "    scw_list_str = \",\".join(sorted(scw_pick))\n",
    "else:\n",
    "    scw_list_str=\",\".join([s+\".\"+\"001\" for s in sorted(set( sorted(scwlist)  ))])\n",
    "\n",
    "#print(len(scw_list_str))\n",
    "\n",
    "scw_list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oda_api.api\n",
    "import importlib\n",
    "importlib.reload(oda_api)\n",
    "\n",
    "# osa versions with '-' use ic root version, only available on staging-1-3\n",
    "print('will find appropriate API for OSA version', osa_version)\n",
    "if '-' in osa_version:\n",
    "    print('osa version has subversion - will use staging-1-3')\n",
    "    disp = oda_api.api.DispatcherAPI(url=\"http://in.internal.odahub.io/staging-1-3/dispatcher\")\n",
    "else:\n",
    "    try:\n",
    "        disp = oda_api.api.DispatcherAPI(url=\"http://dispatcher.staging.internal.odahub.io\")\n",
    "        disp.get_instrument_description(\"isgri\")    \n",
    "    except:\n",
    "        try:\n",
    "            disp = oda_api.api.DispatcherAPI(url='https://www.astro.unige.ch/cdci/astrooda/dispatch-data')\n",
    "            disp.get_instrument_description(\"isgri\")\n",
    "        except:\n",
    "            raise ConnectionError\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file_list =  glob.glob(subcase_dir+\"/api_cat_str_*.txt\")\n",
    "if len(api_file_list) == 0:\n",
    "    api_cat_exist = False\n",
    "else:\n",
    "    print('Found api catalog in file ', api_file_list[0])\n",
    "    api_cat_exist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not api_cat_exist:\n",
    "\n",
    "    for c_emin in [28]:\n",
    "\n",
    "        image = disp.get_product(instrument=\"isgri\", \n",
    "                         product=\"isgri_image\", \n",
    "                         product_type=\"Real\", \n",
    "                         osa_version=osa_version,\n",
    "                         E1_keV=np.round(c_emin),\n",
    "                         E2_keV=80.0,\n",
    "                         scw_list=scw_list_str)\n",
    "\n",
    "        sources=image.dispatcher_catalog_1.table[image.dispatcher_catalog_1.table['significance']>=6.0]\n",
    "        #source = sources[sources['src_names']==source_name]\n",
    "        unique_sources=table.unique(sources, keys=['src_names'])\n",
    "        \n",
    "        #print(source)\n",
    "\n",
    "#         d=image.mosaic_image_0.data_unit[1].data\n",
    "\n",
    "\n",
    "#         img=np.array(d.data)\n",
    "\n",
    "#         m_bkg=img<10\n",
    "#         m_bkg&=img!=0\n",
    "\n",
    "#         img_std = np.std(img[m_bkg])\n",
    "\n",
    "#         img[np.array(img)>img_std*5]=img_std*5\n",
    "\n",
    "        #plt.imshow(img)\n",
    "\n",
    "#         by_lt['%.10lg'%c_emin]=dict(\n",
    "#             emin=c_emin,            \n",
    "#             imgstd=img_std,\n",
    "#         )\n",
    "#         by_lt['%.10lg'%c_emin].update(dict([(n, source[n]) for n in source.colnames]))\n",
    "\n",
    "        \n",
    "#     for ltb, c in by_lt.items():\n",
    "#         print(lt, c['significance'],c['significance']/c['imgstd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removes new sources and adds our if not found\n",
    "if not api_cat_exist:\n",
    "    FLAG=0\n",
    "    torm=[]\n",
    "    for ID,n in enumerate(unique_sources['src_names']):\n",
    "        if(n[0:3]=='NEW'):\n",
    "            torm.append(ID)\n",
    "        if(n==source_name):\n",
    "            FLAG=1\n",
    "\n",
    "    unique_sources.remove_rows(torm)\n",
    "    nrows=len(unique_sources['src_names'])\n",
    "\n",
    "    if FLAG==0:\n",
    "        unique_sources.add_row((0,source_name,0,ra,dec,0,2,0,0))\n",
    "\n",
    "    image.dispatcher_catalog_1.table = unique_sources\n",
    "\n",
    "    api_cat=image.dispatcher_catalog_1.get_api_dictionary()\n",
    "    \n",
    "    with open(subcase_dir+\"/api_cat_str_%s.txt\"%(source_name.replace(' ','_').replace('+','p')),'w') as f: \n",
    "        f.write(api_cat) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if api_cat_exist:\n",
    "    with open(api_file_list[0]) as ff:\n",
    "        api_cat = json.dumps(json.load(ff))\n",
    "    print(api_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = disp.get_product(instrument=\"isgri\", \n",
    "                 product=\"isgri_spectrum\", \n",
    "                 product_type=\"Real\", \n",
    "                 osa_version=osa_version,\n",
    "                 E1_keV=25.0,\n",
    "                 E2_keV=80.0,\n",
    "                 scw_list=scw_list_str,\n",
    "                 selected_catalog=api_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specprod=[l for l in spectrum._p_list if l.meta_data['src_name'] == source_name]    \n",
    "\n",
    "spec_fn=\"/tmp/isgri_spectrum_{}.fits\".format(source_name.replace(' ', '_').replace('+','p'))\n",
    "arf_fn=\"/tmp/isgri_arf_{}.fits\".format(source_name.replace(' ', '_').replace('+','p'))\n",
    "rmf_fn=\"/tmp/isgri_rmf_{}.fits\".format(source_name.replace(' ', '_').replace('+','p'))\n",
    "\n",
    "specprod[0].write_fits_file(spec_fn)\n",
    "specprod[1].write_fits_file(arf_fn)\n",
    "specprod[2].write_fits_file(rmf_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "for s, b, r, a in zip(reference_spectra, reference_backs, reference_rmfs, reference_arfs):\n",
    "\n",
    "    fs=fits.open(reference_dir+\"/\"+s)\n",
    "    fr=fits.open(reference_dir+\"/\"+r)\n",
    "    fb=fits.open(reference_dir+\"/\"+b)\n",
    "    fa=fits.open(reference_dir+\"/\"+a)\n",
    "    \n",
    "\n",
    "    fs[2].header['RESPFILE'] = 'NONE'\n",
    "    fs[2].header['ANCRFILE'] = 'NONE'\n",
    "    fs[2].header['BACKFILE'] = 'NONE'\n",
    "    \n",
    "    #f[2].header['RESPFILE']\n",
    "    if \"A\" in s:\n",
    "        fn = \"reference_spec_A.fits\"\n",
    "    else:\n",
    "        fn = \"reference_spec_B.fits\"\n",
    "        \n",
    "    print(\"writing\", fn)        \n",
    "    fs.writeto(fn, overwrite=True)\n",
    "    \n",
    "    if 'A' in r:\n",
    "        fn = \"reference_rmf_A.fits\"\n",
    "    else:\n",
    "        fn = \"reference_rmf_B.fits\"\n",
    "        \n",
    "    print(\"writing\", fn)        \n",
    "    fr.writeto(fn, overwrite=True)\n",
    "    \n",
    "    if 'A' in b:\n",
    "        fn = \"reference_bkg_A.fits\"\n",
    "    else:\n",
    "        fn = \"reference_bkg_B.fits\"\n",
    "\n",
    "    print(\"writing\", fn)        \n",
    "    fb.writeto(fn, overwrite=True)\n",
    "    \n",
    "    if 'A' in a:\n",
    "        fn = \"reference_arf_A.fits\"\n",
    "    else:\n",
    "        fn = \"reference_arf_B.fits\"\n",
    "        \n",
    "    print(\"writing\")\n",
    "    fa.writeto(fn, overwrite=True)\n",
    "    \n",
    "    fs.close()\n",
    "    fb.close()\n",
    "    fa.close()\n",
    "    fr.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputs"
    ]
   },
   "outputs": [],
   "source": [
    "reference_spec_A=\"reference_spec_A.fits\"\n",
    "reference_spec_B=\"reference_spec_B.fits\"\n",
    "reference_arf_A=\"reference_arf_A.fits\"\n",
    "reference_arf_B=\"reference_arf_B.fits\"\n",
    "reference_rmf_A=\"reference_rmf_A.fits\"\n",
    "reference_rmf_B=\"reference_rmf_B.fits\"\n",
    "reference_bkg_A=\"reference_bkg_A.fits\"\n",
    "reference_bkg_B=\"reference_bkg_B.fits\"\n",
    "isgri_spec=spec_fn\n",
    "isgri_arf=arf_fn\n",
    "isgri_rmf=rmf_fn"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
